# âš¡ DevJobs Hunter - Moteur de Recherche d'Emploi IT

Un moteur de recherche d'emploi cyberpunk pour les dÃ©veloppeurs et professionnels de l'IT. Interface nÃ©on/hacker style Tron + agrÃ©gation multi-sources (APIs + scraping).

## ğŸ¨ Design

- **ThÃ¨me cyberpunk** : grille animÃ©e Tron, nÃ©ons cyan/rose/violet, typographie Orbitron
- **CatÃ©gories IT complÃ¨tes** : Frontend, Backend, Fullstack, DevOps, Data, ML/AI, Security, etc.
- **UI responsive** : formulaire avancÃ© + cards d'offres interactives avec score de matching

## ğŸš€ Stack Technique

### Backend
- **FastAPI** : API REST moderne et rapide
- **Pydantic** : validation de donnÃ©es
- **Connecteurs multi-sources** :
  - France Travail API (stub)
  - Adzuna API (stub)
  - EURES API (stub)
  - **Scraping actif** : Welcome to the Jungle, Remotive.io, **APEC**, **Indeed**
- **Scrapeur hebdomadaire** : alimentation automatique BDD
- **DÃ©duplication** : hash + similaritÃ© textuelle
- **Scoring CV** : matching keywords + contraintes (remote/contrat/salaire/pays)

### Frontend
- **Next.js 14** (App Router)
- **TypeScript**
- **CSS custom** : animations, effets nÃ©on, grid Tron
- **Fonts** : Orbitron (titres), Roboto Mono (texte)

## ğŸ“¦ Installation

### Backend

```bash
cd backend
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend

```bash
cd frontend
npm install
npm run dev
```

Le frontend sera accessible sur http://localhost:3000 (ou 3001 si 3000 occupÃ©).

## ğŸ”§ Configuration

### Variables d'environnement (optionnel)

Backend `.env` :
```bash
# APIs (stubs par dÃ©faut, scraping actif)
FRANCE_TRAVAIL_API_KEY=your_key
ADZUNA_APP_ID=your_id
ADZUNA_APP_KEY=your_key
EURES_API_KEY=your_key

# LLM enrichissement (optionnel)
OPENROUTER_API_KEY=your_key

# Base de donnÃ©es (futur)
DATABASE_URL=postgresql://user:pass@localhost:5432/jobs
```

Frontend `.env.local` :
```bash
NEXT_PUBLIC_API_BASE=http://localhost:8000
```

## ğŸ¯ FonctionnalitÃ©s

### Mode Sans API (Scraping)
Par dÃ©faut, le moteur fonctionne **sans clÃ©s API** grÃ¢ce au scraping :
- **Welcome to the Jungle** (France) : offres tech franÃ§aises
- **Remotive.io** (International) : jobs remote IT
- **APEC** (France) : offres cadres
- **Indeed** (Multi-pays) : agrÃ©gateur global

Les scrapers sont configurÃ©s dans `backend/app/connectors/` avec gestion d'erreurs robuste.

### Scraping Hebdomadaire Automatique ğŸ•

Un systÃ¨me de scraping pÃ©riodique alimente la BDD automatiquement :

```bash
# Test manuel
cd backend
python run_weekly_scraper.py
```

**Automatisation** : voir [WEEKLY_SCRAPER.md](WEEKLY_SCRAPER.md) pour configurer Windows Task Scheduler ou cron Linux/Mac.

Avantages :
- âœ… Recherche utilisateur ultra-rapide (lecture BDD)
- âœ… Historique des offres
- âœ… Pas de surcharge des sites externes
- âœ… 20+ requÃªtes prÃ©dÃ©finies (python, react, devops, data, etc.)

### CatÃ©gories IT Disponibles
- Frontend Dev, Backend Dev, Fullstack Dev
- Mobile Dev (iOS/Android/React Native)
- DevOps/SRE, Cloud Architect
- Data Engineer, Data Scientist, ML Engineer, AI Researcher
- QA/Test Engineer, Security Engineer
- Blockchain Dev, Game Dev, Embedded/IoT
- Tech Lead, Engineering Manager, Product Manager
- UI/UX Designer, Solutions Architect

### Filtres Recherche
- **Mots-clÃ©s** : python, react, kubernetes, etc.
- **CatÃ©gories** : sÃ©lection multiple
- **Pays** : codes ISO (fr, de, us, etc.)
- **Contrat** : CDI, CDD, Freelance, Stage
- **Remote** : full remote, hybride, sur site
- **Salaire min** : en â‚¬/an
- **Profil CV** : rÃ©sumÃ© compÃ©tences pour scoring

### Pipeline de DonnÃ©es
1. **Ingestion** : appel APIs + scraping parallÃ¨le
2. **Normalisation** : schÃ©ma `JobPosting` unifiÃ©
3. **DÃ©duplication** : hash (source+titre+entreprise+ville)
4. **Scoring** : 
   - Base 50 + bonus keywords prÃ©sents dans CV
   - PÃ©nalitÃ©s si contraintes non respectÃ©es (remote/contrat/pays/salaire)
5. **Ranking** : tri dÃ©croissant par score
6. **Restitution** : JSON + explications (reasons)

## ğŸ› ï¸ DÃ©veloppement

### Ajouter un nouveau connecteur scraping

Ã‰diter `backend/app/connectors/scraper.py` :

```python
def _scrape_nouveau_site(query: str) -> List[JobPosting]:
    jobs = []
    try:
        url = f"https://example.com/jobs?q={quote_plus(query)}"
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        
        # Parser les offres
        for card in soup.select(".job-card"):
            title = card.select_one(".title").get_text(strip=True)
            company = card.select_one(".company").get_text(strip=True)
            # ...
            jobs.append(JobPosting(...))
    except Exception as e:
        print(f"[scrape error] {e}")
    return jobs
```

Puis appeler dans `fetch_scraping()`.

### Remplacer stubs par vraies APIs

Ã‰diter `backend/app/connectors/france_travail.py` (ou adzuna/eures) :

```python
def fetch_jobs(query: str, limit: int = 20) -> List[JobPosting]:
    # Remplacer mock par vrais appels
    url = "https://api.francetravail.io/partenaire/offresdemploi/v2/offres/search"
    headers = {"Authorization": f"Bearer {FRANCE_TRAVAIL_API_KEY}"}
    params = {"motsCles": query, "range": f"0-{limit}"}
    res = requests.get(url, headers=headers, params=params)
    data = res.json()
    # Parser et mapper vers JobPosting
```

## ğŸ“Š Architecture Cible (Future)

- **Postgres + pgvector** : stockage persistant + recherche vectorielle
- **Celery + Redis** : jobs batch rÃ©currents (refresh offres)
- **LLM enrichissement** : extraction salaire/remote/skills via OpenRouter
- **Alertes** : email/webhook/Telegram sur nouvelles offres matchÃ©es
- **UI avancÃ©e** : filtres sauvegardÃ©s, historique candidatures, export CSV/Notion

## ğŸ¨ Personnalisation UI

Les variables CSS sont dans `frontend/app/globals.css` :

```css
:root {
  --neon-cyan: #00f0ff;
  --neon-pink: #ff00ff;
  --neon-purple: #b721ff;
  --neon-green: #39ff14;
  /* ... */
}
```

Modifier couleurs, animations, fonts selon vos prÃ©fÃ©rences.

## ğŸ“ Licence

MIT - Projet Ã©ducatif/portfolio. Respectez les CGU des sites scrapÃ©s.

## ğŸ“š Documentation ComplÃ¨te

- **[QUICKSTART.md](QUICKSTART.md)** : DÃ©marrage rapide en 3 Ã©tapes
- **[WEEKLY_SCRAPER.md](WEEKLY_SCRAPER.md)** : Configuration scraping automatique hebdomadaire
- **[IT_CATEGORIES.md](IT_CATEGORIES.md)** : Liste exhaustive des 50+ rÃ´les IT disponibles
- **[SCRAPING_SOURCES.md](SCRAPING_SOURCES.md)** : Sites scrapables + templates code

## ğŸ§ª Tests

Tester tous les connecteurs :

```bash
cd backend
python test_scraper.py
```

RÃ©sultat attendu :
```
âœ… France Travail (stub)
âœ… Adzuna (stub)
âœ… EURES (stub)
âœ… Scraping (WTTJ + Remotive)
âœ… APEC
âœ… Indeed

Success: 6/6
ğŸ‰ All connectors working! ğŸ‰
```

## ğŸ¤ Contribution

1. Fork le repo
2. CrÃ©er une branche feature (`git checkout -b feat/new-connector`)
3. Commit (`git commit -m 'Add new connector'`)
4. Push (`git push origin feat/new-connector`)
5. Ouvrir une Pull Request

---

**Bon hunt ! ğŸš€âš¡**
